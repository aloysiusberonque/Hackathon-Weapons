{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f61d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
      "                                              0.0/72.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 72.0/72.0 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\aloys\\appdata\\roaming\\python\\python310\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aloys\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.64.1)\n",
      "Collecting aiohttp (from openai)\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aloys\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aloys\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aloys\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aloys\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aloys\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "                                              0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aloys\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dfdc7",
   "metadata": {},
   "source": [
    "## 1. User Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d401d8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Introduce me ChatGPT in a pirate way\n",
      "ChatGPT: , {\n",
      "  \"content\": \"Ahoy, me hearty! 'tis I, yer trusty chatbot, ChatGPT, here to swashbuckle me way into yer heart and give ye answers to all yer queries! I be sailin' the seven seas of knowledge, ready to plunder the treasure trove of information. Whether ye be wantin' to know about history, science, or even the best way to make yer seaweed stew, I be here to help ye out, maties! So hoist the Jolly Roger, and let's embark on a voyage of discovery together! Arrr!\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "content = input(\"User: \")\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": content}\n",
    "  ]\n",
    ")\n",
    "chat_response = completion.choices[0].message\n",
    "print(f'ChatGPT: , {chat_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cbea9",
   "metadata": {},
   "source": [
    "## 2. System Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3651bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You're a recruiter who asks tough interview questions\"}\n",
    "#     {\"role\": \"system\", \"content\": \"You're a kind helpful assistant\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33b3e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "ChatGPT: , {\n",
      "  \"content\": \"Hi! As a recruiter, I ask tough interview questions to understand a candidate's abilities, experiences, and attitudes. Are you ready for some tough interview questions?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "content = input(\"User: \")\n",
    "messages.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "chat_response = completion.choices[0].message\n",
    "print(f'ChatGPT: , {chat_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da3089",
   "metadata": {},
   "source": [
    "## 3. Assistant Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fc5b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You're a recruiter who asks tough interview questions. You can ask new questions after my response\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b2113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "ChatGPT: , Hi! Let's get started with the interview. Please tell me about a time when you faced a difficult challenge at work and how you overcame it.\n",
      "User: I did ask my co workers for advices\n",
      "ChatGPT: , That's a good start! Can you provide more details about the challenge you faced and how your coworkers' advice helped you overcome it? And also, what was the outcome of the situation?\n",
      "User: They did teach me the concepts and sent me some courses\n",
      "ChatGPT: , That's great to hear that your coworkers supported you by providing you with training and help to overcome the challenge. Can you tell me specifically what was the challenge you faced? What was your role in this situation and what were the steps you took to address it? And, what was the outcome in the end?\n",
      "User: Secret\n",
      "ChatGPT: , I understand. Let's move on to another question. Can you tell me about a project that you spearheaded and what were the results? What was your role in the project and how did you make it successful?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "while True:\n",
    "    content = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages\n",
    "    )\n",
    "\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    print(f'ChatGPT: , {chat_response}')\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385e9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
